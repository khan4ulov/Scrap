{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to Restaurants_dataatninfo.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Base URL of the webpage to scrape\n",
    "base_url = \"https://www.atninfo.com/uae/all/restaurants-1239\"\n",
    "\n",
    "# Function to scrape restaurant names, P.O. Box numbers, area, location, phone numbers, mobile numbers, and categories from a given page number\n",
    "def scrape_restaurant_info(page_num, session):\n",
    "    if page_num == 1:\n",
    "        url = f\"{base_url}\"\n",
    "    else:\n",
    "        url = f\"{base_url}/{page_num}\"\n",
    "\n",
    "    response = session.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        restaurant_divs = soup.find_all('div', class_='col-7 center-vertically')\n",
    "\n",
    "        if not restaurant_divs:  # No more restaurants found, stop scraping\n",
    "            return None\n",
    "\n",
    "        info = []\n",
    "        for div in restaurant_divs:\n",
    "            name_tag = div.find('h2', itemprop='name')\n",
    "            if name_tag:\n",
    "                name = name_tag.get_text(strip=True)\n",
    "\n",
    "                # Find the parent div that contains the P.O. Box, area, location, phone number, mobile number, and category information\n",
    "                parent_div = div.find_parent('div', class_='row').find_next_siblings('div', class_='row')\n",
    "\n",
    "                po_box = \"N/A\"\n",
    "                area = \"N/A\"\n",
    "                location = \"N/A\"\n",
    "                phone = \"N/A\"\n",
    "                mobile = \"N/A\"\n",
    "                category = \"Restaurants\"  # Default value for category\n",
    "\n",
    "                for sibling_div in parent_div:\n",
    "                    po_box_tag = sibling_div.find('span', itemprop='postalCode')\n",
    "                    if po_box_tag:\n",
    "                        po_box = po_box_tag.get_text(strip=True)\n",
    "                        if not po_box:\n",
    "                            po_box = \"N/A\"\n",
    "\n",
    "                    area_tag = sibling_div.find('span', itemprop='addressLocality')\n",
    "                    if area_tag:\n",
    "                        area = area_tag.get_text(strip=True)\n",
    "                        if not area:\n",
    "                            area = \"N/A\"\n",
    "\n",
    "                    location_tag = sibling_div.find('span', itemprop='streetAddress')\n",
    "                    if location_tag:\n",
    "                        location = location_tag.get_text(strip=True)\n",
    "\n",
    "                    phone_tag = sibling_div.find('span', itemprop='telephone')\n",
    "                    if phone_tag:\n",
    "                        phone = phone_tag.get_text(strip=True)\n",
    "\n",
    "                    mobile_tag = sibling_div.find('a', class_='mobileClick')\n",
    "                    if mobile_tag:\n",
    "                        mobile = mobile_tag.find_next('span').get_text(strip=True)\n",
    "\n",
    "                    # Extract category information from the provided snippet\n",
    "                    category_tags = sibling_div.find_all('a', class_='badge-list clicktoscroll clickCats')\n",
    "                    if category_tags:\n",
    "                        categories = [tag.get_text(strip=True) for tag in category_tags]\n",
    "                        category = \", \".join(categories)\n",
    "\n",
    "                info.append((name, po_box, area, location, phone, mobile, category))\n",
    "\n",
    "        return info\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page_num}. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Number of pages to scrape\n",
    "num_pages = 120  # Adjust this number based on how many pages you want to attempt to scrape\n",
    "\n",
    "# Create a session for efficient HTTP requests\n",
    "session = requests.Session()\n",
    "\n",
    "all_restaurant_info = []\n",
    "for page in range(1, num_pages + 1):\n",
    "    info = scrape_restaurant_info(page, session)\n",
    "    if info is None:  # Stop scraping if no more restaurant entries are found\n",
    "        break\n",
    "    all_restaurant_info.extend(info)\n",
    "\n",
    "# Close the session\n",
    "session.close()\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(\"Restaurants_dataatninfo.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header row\n",
    "    writer.writerow([\"Name\", \"P.O. Box\", \"Area\", \"Location\", \"Phone\", \"Mobile\", \"Category\"])\n",
    "    # Write data rows\n",
    "    for name, po_box, area, location, phone, mobile, category in all_restaurant_info:\n",
    "        writer.writerow([name, po_box, area, location, phone, mobile, category])\n",
    "\n",
    "print(\"Data has been saved to Restaurants_dataatninfo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa427f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
